{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f8b73e9",
   "metadata": {},
   "source": [
    "# SimCLR Model Building and Training\n",
    "This notebook provides a full, reproducible SimCLR (contrastive) training pipeline that adapts to whether your dataset is tabular or image-based.\n",
    "\n",
    "Primary features:\n",
    "- Detects cleaned dataset `ztf_image_search_results_full_cleaned.csv` in the workspace root.\n",
    "- Uses an image-based ResNet encoder when an `image_path` column exists; otherwise uses an MLP encoder for tabular features.\n",
    "- Implements contrastive augmentations for both modalities, NT-Xent loss, training loop, checkpointing, and a linear evaluation cell.\n",
    "\n",
    "Run each cell sequentially. If you want me to start training now, confirm and I will run the training cells (this can be long-running)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd842c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: install required packages if missing (uncomment to run).\n",
    "# Note: install the appropriate torch build for your machine (cpu/cuda). Example (CPU):\n",
    "# !pip install -q torch torchvision pandas scikit-learn tqdm\n",
    "# If you need umap or other extras for visualization:\n",
    "# !pip install -q umap-learn seaborn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4468aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and helper functions\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "# For image support if present\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_PATH = 'ztf_image_search_results_full_cleaned.csv'\n",
    "CHECKPOINT_DIR = 'checkpoints'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50\n",
    "LR = 1e-3\n",
    "PROJ_DIM = 128  # projection head output dim\n",
    "TEMPERATURE = 0.5\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de27fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe and auto-detect data modality (image vs tabular)\n",
    "assert os.path.exists(DATA_PATH), f\"Data file {DATA_PATH} not found in workspace.\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Loaded', DATA_PATH, 'with shape', df.shape)\n",
    "# Detect common image path column names\n",
    "image_cols = [c for c in df.columns if 'image' in c.lower() or 'img' in c.lower() or 'filepath' in c.lower()]\n",
    "has_images = len(image_cols) > 0\n",
    "print('Detected image columns:', image_cols)\n",
    "# Try to find object id column to group time-series if available\n",
    "id_cols = [c for c in df.columns if c.lower() in ('objectid','objid','object_id','oid','sourceid','source_id')]\n",
    "obj_id_col = id_cols[0] if len(id_cols) else None\n",
    "print('Using object id column:', obj_id_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52507019",
   "metadata": {},
   "source": [
    "## Augmentations and Contrastive Dataset\n",
    "The dataset returns two augmented views for each sample. For images we use torchvision transforms; for tabular data we use simple numeric augmentations (gaussian noise, feature dropout, scaling jitter). Adjust augmentations to taste for astronomy domain knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabular augmentations\n",
    "def tabular_augment(x, noise_std=0.01, drop_prob=0.05, scale_jitter=0.02):\n",
    "    x = x.copy().astype('float32')\n",
    "    # gaussian noise proportional to value scale\n",
    "    noise = np.random.normal(0, noise_std, size=x.shape) * (np.abs(x) + 1e-6)\n",
    "    x = x + noise\n",
    "    # random feature dropout\n",
    "    mask = np.random.rand(*x.shape) > drop_prob\n",
    "    x = x * mask\n",
    "    # small multiplicative jitter\n",
    "    jitter = 1.0 + np.random.normal(0, scale_jitter, size=x.shape)\n",
    "    x = x * jitter\n",
    "    return x\n",
    "\n",
    "# Image augmentations (default to common SimCLR)\n",
    "def make_image_transform(sz=224):\n",
    "    return T.Compose([\n",
    "        T.RandomResizedCrop(sz),\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.ColorJitter(0.4,0.4,0.4,0.1),\n",
    "        T.RandomGrayscale(p=0.2),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "    ])\n",
    "\n",
    "# Contrastive Dataset that returns (x_i, x_j) pair and optionally a label if available\n",
    "class ContrastiveDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols=None, image_col=None, obj_id_col=None, transform=None, tabular_aug=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_col = image_col\n",
    "        self.obj_id_col = obj_id_col\n",
    "        self.transform = transform\n",
    "        self.tabular_aug = tabular_aug\n",
    "        if feature_cols is None and image_col is None:\n",
    "            # automatic feature selection: numeric columns\n",
    "            self.feature_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        else:\n",
    "            self.feature_cols = feature_cols\n",
    "        # keep labels if present\n",
    "        self.label_col = None\n",
    "        for c in ('label','target','class'):\n",
    "            if c in self.df.columns:\n",
    "                self.label_col = c\n",
    "                break\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        if self.image_col is not None and pd.notna(row[self.image_col]):\n",
    "            path = row[self.image_col]\n",
    "            img = Image.open(path).convert('RGB')\n",
    "            x1 = self.transform(img)\n",
    "            x2 = self.transform(img)\n",
    "            return x1, x2, (row[self.label_col] if self.label_col is not None else -1)\n",
    "        else:\n",
    "            x = row[self.feature_cols].values.astype('float32')\n",
    "            x1 = tabular_augment(x) if self.tabular_aug is None else self.tabular_aug(x)\n",
    "            x2 = tabular_augment(x) if self.tabular_aug is None else self.tabular_aug(x)\n",
    "            return torch.from_numpy(x1), torch.from_numpy(x2), (row[self.label_col] if self.label_col is not None else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74c3aab",
   "metadata": {},
   "source": [
    "## Model: flexible encoder + projection head\n",
    "- For images use a ResNet50 backbone (no final FC) and a small MLP projection head.\n",
    "- For tabular data use a 3-layer MLP encoder and a projection head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d080a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder and SimCLR model definitions\n",
    "class TabularEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=512, out_dim=256):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, in_dim, proj_dim=PROJ_DIM):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, in_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_dim, proj_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class SimCLRModel(nn.Module):\n",
    "    def __init__(self, encoder, feat_dim, proj_dim=PROJ_DIM):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.proj = ProjectionHead(feat_dim, proj_dim)\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z = self.proj(h)\n",
    "        z = F.normalize(z, dim=1)\n",
    "        return h, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07bee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NT-Xent loss (normalized temperature-scaled cross entropy)\n",
    "def nt_xent_loss(z_i, z_j, temperature=TEMPERATURE):\n",
    "    # z_i, z_j: (N, D) normalized\n",
    "    N = z_i.size(0)\n",
    "    z = torch.cat([z_i, z_j], dim=0)  # 2N x D\n",
    "    sim = torch.matmul(z, z.T)  # 2N x 2N\n",
    "    sim /= temperature\n",
    "    # mask to remove similarity with itself\n",
    "    mask = (~torch.eye(2*N, dtype=torch.bool)).to(device)\n",
    "    exp_sim = torch.exp(sim) * mask\n",
    "    # positive pairs: i with i+N and vice versa\n",
    "    positives = torch.exp((torch.sum(z_i * z_j, dim=-1) / temperature))\n",
    "    positives = torch.cat([positives, positives], dim=0)\n",
    "    denom = exp_sim.sum(dim=1)\n",
    "    loss = -torch.log(positives / denom)\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d95a706",
   "metadata": {},
   "source": [
    "## Prepare dataset and model instance\n",
    "Create the dataset and choose encoder depending on modality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e9ce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset (stratify if label exists)\n",
    "if 'label' in df.columns or 'target' in df.columns or 'class' in df.columns:\n",
    "    strat_col = [c for c in ('label','target','class') if c in df.columns][0]\n",
    "    train_df, val_df = train_test_split(df, test_size=0.1, random_state=RANDOM_SEED, stratify=df[strat_col])\n",
    "else:\n",
    "    train_df, val_df = train_test_split(df, test_size=0.1, random_state=RANDOM_SEED)\n",
    "\n",
    "if has_images:\n",
    "    sz = 224\n",
    "    transform = make_image_transform(sz=sz)\n",
    "    train_ds = ContrastiveDataset(train_df, image_col=image_cols[0], obj_id_col=obj_id_col, transform=transform)\n",
    "    val_ds = ContrastiveDataset(val_df, image_col=image_cols[0], obj_id_col=obj_id_col, transform=transform)\n",
    "    # encoder: ResNet50 without final layer\n",
    "    base = models.resnet50(pretrained=False)\n",
    "    # remove fc\n",
    "    modules = list(base.children())[:-1]\n",
    "    class ResNetEncoder(nn.Module):\n",
    "        def __init__(self, modules, feat_dim=2048):\n",
    "            super().__init__()\n",
    "            self.backbone = nn.Sequential(*modules)\n",
    "            self.feat_dim = feat_dim\n",
    "        def forward(self, x):\n",
    "            x = self.backbone(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            return x\n",
    "    encoder = ResNetEncoder(modules).to(device)\n",
    "    feat_dim = encoder.feat_dim\n",
    "else:\n",
    "    feature_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    # drop label column if present from features\n",
    "    for c in ('label','target','class'):\n",
    "        if c in feature_cols:\n",
    "            feature_cols.remove(c)\n",
    "    print('Tabular feature dim:', len(feature_cols))\n",
    "    train_ds = ContrastiveDataset(train_df, feature_cols=feature_cols, obj_id_col=obj_id_col)\n",
    "    val_ds = ContrastiveDataset(val_df, feature_cols=feature_cols, obj_id_col=obj_id_col)\n",
    "    encoder = TabularEncoder(input_dim=len(feature_cols)).to(device)\n",
    "    feat_dim = encoder.net[-1].out_features if hasattr(encoder.net[-1],'out_features') else 256\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=0)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, num_workers=0)\n",
    "\n",
    "model = SimCLRModel(encoder, feat_dim, proj_dim=PROJ_DIM).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "print('Model prepared. Params:', sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da124fe",
   "metadata": {},
   "source": [
    "## Training loop (contrastive pretraining)\n",
    "The loop runs forward for two views, computes NT-Xent loss and updates weights. Checkpointing is done every few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff5330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop (lightweight, modify EPOCHS/BATCH_SIZE as needed)\n",
    "best_loss = float('inf')\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch}/{EPOCHS}')\n",
    "    for (x1, x2, _) in pbar:\n",
    "        # move to device and flatten for tabular case\n",
    "        if not has_images:\n",
    "            x1 = x1.float().to(device)\n",
    "            x2 = x2.float().to(device)\n",
    "        else:\n",
    "            x1 = x1.to(device)\n",
    "            x2 = x2.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        _, z1 = model(x1)\n",
    "        _, z2 = model(x2)\n",
    "        loss = nt_xent_loss(z1, z2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch} average loss: {epoch_loss:.4f}')\n",
    "    # checkpoint\n",
    "    ckpt_path = os.path.join(CHECKPOINT_DIR, f'simclr_epoch_{epoch}.pt')\n",
    "    torch.save({'epoch': epoch, 'model_state': model.state_dict(), 'optimizer_state': optimizer.state_dict()}, ckpt_path)\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, 'simclr_best.pt'))\n",
    "print('Training complete. Best loss:', best_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fd5515",
   "metadata": {},
   "source": [
    "## Linear evaluation (optional)\n",
    "If your dataset contains labels (column `label`/`target`/`class`), train a linear classifier on frozen encoder features to evaluate learned representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1709bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear evaluation: extract features and train a small linear classifier (if labels exist)\n",
    "label_col = None\n",
    "for c in ('label','target','class'):\n",
    "    if c in df.columns:\n",
    "        label_col = c\n",
    "        break\n",
    "if label_col is None:\n",
    "    print('No label column found; skip linear evaluation.')\n",
    "else:\n",
    "    # prepare feature extractors\n",
    "    model.eval()\n",
    "    def extract_features(dataloader):\n",
    "        feats, labs = [], []\n",
    "        with torch.no_grad():\n",
    "            for x1, x2, y in dataloader:\n",
    "                x = x1.float().to(device) if not has_images else x1.to(device)\n",
    "                h, _ = model(x)\n",
    "                feats.append(h.cpu().numpy())\n",
    "                labs.append(np.array(y))\n",
    "        feats = np.concatenate(feats, axis=0)\n",
    "        labs = np.concatenate(labs, axis=0)\n",
    "        return feats, labs\n",
    "    tr_feats, tr_labs = extract_features(DataLoader(train_ds, batch_size=256, num_workers=0))\n",
    "    val_feats, val_labs = extract_features(DataLoader(val_ds, batch_size=256, num_workers=0))\n",
    "    # train a logistic regression on top\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    clf = LogisticRegression(max_iter=2000)\n",
    "    clf.fit(tr_feats, tr_labs)\n",
    "    preds = clf.predict(val_feats)\n",
    "    acc = accuracy_score(val_labs, preds)\n",
    "    print('Linear eval accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c19b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation metrics & confusion matrix plotting (saves figures to `figures/`)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "\n",
    "if label_col is None:\n",
    "    print('No label column available â€” skipping detailed validation metrics.')\n",
    "else:\n",
    "    # Ensure we have extracted validation features and labels\n",
    "    try:\n",
    "        val_feats, val_labs\n",
    "    except NameError:\n",
    "        val_feats, val_labs = extract_features(DataLoader(val_ds, batch_size=256, num_workers=0))\n",
    "    try:\n",
    "        preds\n",
    "    except NameError:\n",
    "        preds = clf.predict(val_feats)\n",
    "    # If classifier supports predict_proba, get probabilities for ROC AUC when binary\n",
    "    probs = None\n",
    "    if hasattr(clf, 'predict_proba'):\n",
    "        try:\n",
    "            probs = clf.predict_proba(val_feats)\n",
    "        except Exception:\n",
    "            probs = None\n",
    "    # Basic scores\n",
    "    acc = accuracy_score(val_labs, preds)\n",
    "    precision = precision_score(val_labs, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(val_labs, preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(val_labs, preds, average='weighted', zero_division=0)\n",
    "    print(f'Accuracy: {acc:.4f}  Precision: {precision:.4f}  Recall: {recall:.4f}  F1 (weighted): {f1:.4f}')\n",
    "    # Classification report\n",
    "    creport = classification_report(val_labs, preds, zero_division=0)\n",
    "    print('Classification report:\\n', creport)\n",
    "    # Save report to file\n",
    "    with open('figures/classification_report.txt', 'w') as f:\n",
    "        f.write('Accuracy: {:.4f}\\nPrecision: {:.4f}\\nRecall: {:.4f}\\nF1 (weighted): {:.4f}\\n\\n'.format(acc, precision, recall, f1))\n",
    "        f.write(creport)\n",
    "    # Confusion matrix\n",
    "    labels_unique = np.unique(val_labs)\n",
    "    cm = confusion_matrix(val_labs, preds, labels=labels_unique)\n",
    "    fig, ax = plt.subplots(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, xticklabels=labels_unique, yticklabels=labels_unique)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    fig.savefig('figures/confusion_matrix.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    # ROC AUC for binary tasks if probabilities available\n",
    "    if probs is not None and len(labels_unique) == 2:\n",
    "        try:\n",
    "            pos_prob = probs[:, 1]\n",
    "            auc = roc_auc_score(val_labs, pos_prob)\n",
    "            fpr, tpr, _ = roc_curve(val_labs, pos_prob)\n",
    "            plt.figure(); plt.plot(fpr, tpr, label=f'ROC AUC = {auc:.3f}'); plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('ROC Curve'); plt.legend(); plt.grid(True)\n",
    "            plt.savefig('figures/roc_curve.png', bbox_inches='tight')\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print('Could not compute ROC AUC:', e)\n",
    "    print('Saved validation figures and report to `figures/`')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a24f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison: train several classifiers on frozen features and visualize accuracy/F1\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "\n",
    "# Ensure features and labels exist (extract if necessary)\n",
    "try:\n",
    "    tr_feats, tr_labs\n",
    "except NameError:\n",
    "    print('Extracting features for train/val for comparison...')\n",
    "    tr_feats, tr_labs = extract_features(DataLoader(train_ds, batch_size=256, num_workers=0))\n",
    "    val_feats, val_labs = extract_features(DataLoader(val_ds, batch_size=256, num_workers=0))\n",
    "\n",
    "# Define candidate models\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=2000),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=200, random_state=RANDOM_SEED, n_jobs=-1),\n",
    "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_SEED),\n",
    "    'SVM': SVC(kernel='rbf', probability=True, random_state=RANDOM_SEED),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'MLP': MLPClassifier(hidden_layer_sizes=(256,), max_iter=500, random_state=RANDOM_SEED)\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, m in models.items():\n",
    "    print(f'Training {name}...')\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        m.fit(tr_feats, tr_labs)\n",
    "    except Exception as e:\n",
    "        print(f'Error training {name}:', e)\n",
    "        continue\n",
    "    dur = time.time() - t0\n",
    "    preds_tmp = m.predict(val_feats)\n",
    "    acc_tmp = accuracy_score(val_labs, preds_tmp)\n",
    "    f1_tmp = f1_score(val_labs, preds_tmp, average='weighted', zero_division=0)\n",
    "    prec_tmp = precision_score(val_labs, preds_tmp, average='weighted', zero_division=0)\n",
    "    rec_tmp = recall_score(val_labs, preds_tmp, average='weighted', zero_division=0)\n",
    "    print(f'{name}: acc={acc_tmp:.4f}, f1={f1_tmp:.4f}, time={dur:.1f}s')\n",
    "    results.append({'model': name, 'accuracy': acc_tmp, 'f1_weighted': f1_tmp, 'precision': prec_tmp, 'recall': rec_tmp, 'time_s': dur})\n",
    "\n",
    "# Save results and plot\n",
    "res_df = pd.DataFrame(results).sort_values('accuracy', ascending=False).reset_index(drop=True)\n",
    "res_df.to_csv('figures/model_comparison.csv', index=False)\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(data=res_df, x='model', y='accuracy', palette='viridis')\n",
    "plt.ylim(0,1)\n",
    "plt.title('Model Accuracy Comparison (validation)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/model_comparison_accuracy.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(data=res_df, x='model', y='f1_weighted', palette='magma')\n",
    "plt.ylim(0,1)\n",
    "plt.title('Model F1 (weighted) Comparison (validation)')\n",
    "plt.ylabel('F1 (weighted)')\n",
    "plt.xlabel('Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/model_comparison_f1.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('Saved model comparison CSV and figures to figures/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11924a4e",
   "metadata": {},
   "source": [
    "## Save final encoder and notes\n",
    "The pretraining creates `simclr_best.pt` in the `checkpoints/` folder. Use the encoder weights for downstream tasks. Remember: to avoid leakage, always fit scalers or other preprocessors only on training splits when performing downstream supervised training."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
