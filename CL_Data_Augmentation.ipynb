{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb6c1a6f",
   "metadata": {},
   "source": [
    "# Data Augmentation for Contrastive Learning (Astronomy)\n",
    "\n",
    "This notebook implements domain-aware augmentations suitable for contrastive learning on astronomical time-series / multi-band observations. Each augmentation is provided as a function that accepts per-object time-series data (pandas DataFrame) and returns an augmented copy.\n",
    "\n",
    "Assumptions: the input DataFrame should contain at least an identifier for the source (e.g. `object_id`), a time column (`time`, `jd`, `mjd`, or `obsdate`), a brightness column (`flux` or `mag`), and a filter/band column (`filter`). Each function performs checks and falls back gracefully if columns are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8e5f7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üìå Cell Description: Helper Utilities for Detecting Key Columns and Sorting by Time</summary>\n",
    "\n",
    "This cell defines small utility functions that make later analysis steps easier and more reliable. Because astronomical datasets can come from different sources and may use different naming conventions for important fields (such as flux, filter, time, or object ID), the first helper function automatically searches for these columns based on common keywords. This ensures that the rest of the pipeline can work consistently, even if the dataset uses slightly different names.\n",
    "\n",
    "The second helper function sorts the dataset by time, which is essential for any analysis that involves the sequence of observations. Many astronomical measurements‚Äîsuch as brightness changes, periodic behavior, or transient events‚Äîdepend strongly on the order in which they were observed. Sorting by time ensures that later steps (such as augmentation, time-series processing, or modeling) operate on correctly ordered data.\n",
    "\n",
    "These two utilities form a foundation for working with real-world astronomical datasets that often vary in structure, naming, and formatting.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **Key Points (Simple & Attractive Explanation)**\n",
    "\n",
    "- **Automatically detects important columns** using keyword searches:  \n",
    "  - **Time column** ‚Üí for ordering observations  \n",
    "  - **Flux/brightness column** ‚Üí for understanding object intensity  \n",
    "  - **Filter/band column** ‚Üí indicates which optical filter the telescope used  \n",
    "  - **Object ID column** ‚Üí identifies which measurements belong to the same celestial object  \n",
    "\n",
    "- **Makes the pipeline flexible**, allowing it to work with datasets that use different naming conventions (e.g., ‚Äúmag‚Äù, ‚Äúflux_calib‚Äù, \"obsdate\").\n",
    "\n",
    "- **Returns a dictionary of detected column names**, used later for augmentation, modeling, and visualization.\n",
    "\n",
    "- **Provides a function to sort observations by time**, ensuring that sequences are analyzed in the correct chronological order.\n",
    "\n",
    "- **Protects against errors**‚Äîif no valid time column exists, the data is returned unchanged.\n",
    "\n",
    "- **Supports time-dependent analysis**, such as:  \n",
    "  - variability studies  \n",
    "  - transient detection  \n",
    "  - light-curve generation  \n",
    "  - sequence modeling (RNN/CNN/LSTM)\n",
    "\n",
    "- **Improves data reliability**, especially when working with raw telescope outputs that may not be pre-sorted.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚≠ê **Why This Cell Is Important for the Research**\n",
    "Astronomical datasets often vary in how they name columns, and many real datasets are not sorted by time. These helper utilities solve two important problems:\n",
    "\n",
    "1. **Column Identification**  \n",
    "   Different surveys use different naming conventions. Automatically detecting flux, time, filter, and ID columns ensures that the rest of the research pipeline functions correctly without requiring manual adjustments. This makes the workflow robust and reusable across many datasets.\n",
    "\n",
    "2. **Ti**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8def02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and helper utilities\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "# Small helper: find time / brightness / filter cols\n",
    "def detect_columns(df):\n",
    "    cols_lower = [c.lower() for c in df.columns]\n",
    "    time_col = next((c for c in df.columns if c.lower() in ['time','obsdate','jd','mjd','epoch']), None)\n",
    "    flux_col = next((c for c in df.columns if c.lower() in ['flux','flux_calib','mag','mag_calib','instrumental_flux']), None)\n",
    "    filter_col = next((c for c in df.columns if 'filter' in c.lower() or 'band' in c.lower()), None)\n",
    "    id_col = next((c for c in df.columns if c.lower() in ['object_id','objid','id','source_id','ipac_gid']), None)\n",
    "    # return 'filter' key (was 'filt' previously) for consistency with augmentation functions\n",
    "    return dict(time=time_col, flux=flux_col, filter=filter_col, id=id_col)\n",
    "\n",
    "# Utility: ensure DataFrame sorted by time for each object\n",
    "def sort_by_time(df, time_col):\n",
    "    if time_col is None or time_col not in df.columns:\n",
    "        return df\n",
    "    try:\n",
    "        return df.sort_values(by=[time_col]).reset_index(drop=True)\n",
    "    except Exception:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b672d9e",
   "metadata": {},
   "source": [
    "## 4.1 Temporal Augmentations\n",
    "- Temporal jittering: add small random noise to timestamps.\n",
    "- Random time shifts: shift the whole sequence by a random amount.\n",
    "- Random cropping: return a contiguous partial subsequence to simulate partial coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d844f7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üìå Cell Description: Time-Based Data Augmentation Functions for Astronomical Time-Series</summary>\n",
    "\n",
    "This cell defines three data-augmentation functions specifically designed for **astronomical time-series data**, such as sequences of observations for the same celestial object taken at different times. Because real telescope data is often sparse, irregular, or limited in length, augmentation helps create realistic variations of existing sequences. This is especially valuable when training machine-learning models, which generally perform better when they have access to more diversity in the training data.\n",
    "\n",
    "Each function carefully modifies the time dimension while preserving the scientific meaning of the sequence. These augmentations are inspired by real observational uncertainties, scheduling variations, and incomplete observation windows commonly seen in astronomy. All functions include logic to handle both datetime timestamps and numerical time formats.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **1. `temporal_jitter()` ‚Äì Adds Small Random Shifts to Individual Time Points**\n",
    "- Adds a tiny random ‚Äújitter‚Äù to each timestamp.  \n",
    "- Mimics natural timing uncertainties found in real observations (e.g., slight delays, instrument timing jitter).  \n",
    "- Uses the **median observation cadence** to scale the jitter realistically.  \n",
    "- Handles both datetime and numeric time columns.  \n",
    "- Keeps the overall sequence shape but makes it slightly irregular, just like real telescope sampling.  \n",
    "- Returns a new DataFrame with slightly perturbed timestamps.\n",
    "\n",
    "**Why it matters:**  \n",
    "Astronomical observations rarely happen at perfectly regular intervals. This augmentation helps models become more robust to irregular timing.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **2. `random_time_shift()` ‚Äì Shifts the Entire Time-Series Forward or Backward**\n",
    "- Applies one random shift to **all** timestamps in the sequence.  \n",
    "- Mimics real-world scenarios where the same pattern could occur earlier or later in time.  \n",
    "- By default, shifts by up to ¬±50% of the sequence duration (or a custom range).  \n",
    "- Works for datetime and numeric timestamps.  \n",
    "- Does **not** distort the spacing between observations‚Äîonly their global position in time.\n",
    "\n",
    "**Why it matters:**  \n",
    "Many astronomical patterns (e.g., flux changes, variability curves) are meaningful regardless of when they occur. Time shifting increases data variety without changing scientific structure.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **3. `random_crop()` ‚Äì Extracts a Random Subsection of the Sequence**\n",
    "- Randomly selects a continuous segment of the time-series.  \n",
    "- Ensures the cropped section contains at least a chosen percentage of the original length (default: 50%).  \n",
    "- Simulates scenarios where telescopes observe only part of an event due to weather, scheduling constraints, or instrument downtime.  \n",
    "- Produces realistic partial sequences for training.\n",
    "\n",
    "**Why it matters:**  \n",
    "Astronomical time-series data is often incomplete. Cropping trains models to handle missing segments and partial observations.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚≠ê **Why These Functions Are Important for the Research**\n",
    "Astronomical surveys often produce **irregular, incomplete, and sparsely sampled time-series**. Machine-learning models struggle when training data is limited or overly uniform. These augmentation functions:\n",
    "\n",
    "- increase dataset size realistically,  \n",
    "- improve model robustness,  \n",
    "- simulate real observation variability,  \n",
    "- help the model generalize to unseen temporal patterns,  \n",
    "- prepare the pipeline for time-series or sequence-based ML tasks (e.g., RNNs, Transformers, CNN-LSTM models).\n",
    "\n",
    "By modifying time in scientifically meaningful ways *without altering the underlying astrophysical behavior*, these augmentations strengthen the reliability and performance of the final model.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ade4ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_jitter(df, time_col, sigma_fraction=0.01, seed=None):\n",
    "    \"\"\"Add Gaussian jitter to timestamps (fraction of median cadence).\n",
    "    Handles datetime-like columns by converting to seconds since epoch, applying jitter,\n",
    "    and converting back to datetimes. Returns DataFrame with same time dtype where possible.\"\"\"\n",
    "    if time_col is None or time_col not in df.columns:\n",
    "        return df\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # try to convert to datetime; if not possible, fall back to numeric as before\n",
    "    try:\n",
    "        times_dt = pd.to_datetime(df[time_col], errors='coerce')\n",
    "        times_s = times_dt.astype('datetime64[ns]').astype('int64') / 1e9\n",
    "        use_datetime = not times_dt.isna().all()\n",
    "    except Exception:\n",
    "        times_s = df[time_col].astype(float).values\n",
    "        use_datetime = False\n",
    "    times = np.array(times_s, dtype=float)\n",
    "    diffs = np.diff(np.sort(times)) if len(times) > 1 else np.array([1.0])\n",
    "    median_cadence = np.median(diffs) if len(diffs) > 0 else 1.0\n",
    "    sigma = sigma_fraction * median_cadence\n",
    "    jitter = rng.normal(loc=0.0, scale=sigma, size=times.shape)\n",
    "    new_times = times + jitter\n",
    "    df_aug = df.copy()\n",
    "    if use_datetime:\n",
    "        df_aug[time_col] = pd.to_datetime(new_times, unit='s')\n",
    "    else:\n",
    "        df_aug[time_col] = new_times\n",
    "    return df_aug\n",
    "\n",
    "def random_time_shift(df, time_col, shift_range=None, seed=None):\n",
    "    \"\"\"Shift the entire sequence by a random amount. shift_range can be (min,max) in same units as time_col. If None, uses +/- 0.5 * duration.\"\"\"\n",
    "    if time_col is None or time_col not in df.columns:\n",
    "        return df\n",
    "    rng = np.random.default_rng(seed)\n",
    "    try:\n",
    "        times_dt = pd.to_datetime(df[time_col], errors='coerce')\n",
    "        times_s = times_dt.astype('datetime64[ns]').astype('int64') / 1e9\n",
    "        use_datetime = not times_dt.isna().all()\n",
    "    except Exception:\n",
    "        times_s = df[time_col].astype(float).values\n",
    "        use_datetime = False\n",
    "    times = np.array(times_s, dtype=float)\n",
    "    duration = times.max() - times.min() if len(times) > 1 else 0.0\n",
    "    if shift_range is None:\n",
    "        shift_range = (-0.5 * duration, 0.5 * duration)\n",
    "    shift = float(rng.uniform(shift_range[0], shift_range[1]))\n",
    "    new_times = times + shift\n",
    "    df_aug = df.copy()\n",
    "    if use_datetime:\n",
    "        df_aug[time_col] = pd.to_datetime(new_times, unit='s')\n",
    "    else:\n",
    "        df_aug[time_col] = new_times\n",
    "    return df_aug\n",
    "\n",
    "def random_crop(df, time_col, min_fraction=0.5, seed=None):\n",
    "    \"\"\"Return a contiguous subsequence of the timeseries (per-object).\"\"\"\n",
    "    if time_col is None or time_col not in df.columns:\n",
    "        return df\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(df)\n",
    "    if n < 2:\n",
    "        return df\n",
    "    min_len = max(1, int(np.ceil(min_fraction * n)))\n",
    "    start = int(rng.integers(0, n - min_len + 1))\n",
    "    end = int(rng.integers(start + min_len, n + 1))\n",
    "    return df.iloc[start:end].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdef201b",
   "metadata": {},
   "source": [
    "## 4.2 Magnitude Augmentations\n",
    "- Magnitude scaling: multiply flux by a random factor.\n",
    "- Brightness warping: apply smooth multiplicative warp across time to simulate calibration/seeing changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bb4793",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üìå Cell Description: Brightness-Based Data Augmentation for Astronomical Light Curves</summary>\n",
    "\n",
    "This cell defines two augmentation methods that modify the **brightness/flux** values in astronomical time-series data. In astronomy, brightness measurements (flux or magnitude) are often affected by real-world factors such as atmospheric conditions, telescope sensitivity, calibration uncertainties, or instrument noise. These augmentations mimic such natural variations, helping machine-learning models learn to be more robust and generalizable when working with real survey data.\n",
    "\n",
    "Both methods preserve the *shape* and *scientific meaning* of the brightness curve, while introducing small, realistic variations. This is important because real telescope observations rarely match perfectly‚Äîbrightness often fluctuates slightly due to observational conditions rather than actual astrophysical change.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **1. `magnitude_scaling()` ‚Äì Uniform Brightness Adjustment**\n",
    "- Applies one random scaling factor to **all flux values** in the sequence.  \n",
    "- The factor is chosen from a user-defined range (default 0.8‚Äì1.2).  \n",
    "- Simulates global brightness changes caused by:  \n",
    "  - calibration errors  \n",
    "  - changes in atmospheric transparency  \n",
    "  - telescope sensitivity fluctuations  \n",
    "- Keeps the overall pattern the same while making the sequence slightly brighter or dimmer.\n",
    "\n",
    "**Why it matters:**  \n",
    "This teaches models that the same astrophysical signal can appear brighter or fainter depending on observing conditions‚Äîan essential property for real survey data.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **2. `brightness_warping()` ‚Äì Smooth Variation of Brightness Over Time**\n",
    "This function introduces a **gradual, smooth distortion** in brightness across the entire timeline.\n",
    "\n",
    "- Converts time into numerical seconds if using datetime.  \n",
    "- Selects a few ‚Äúknots‚Äù (anchor points) across the time span.  \n",
    "- Assigns each knot a random brightness multiplier drawn from a normal distribution.  \n",
    "- Uses interpolation to create a **smooth brightness-warp curve** over time.  \n",
    "- Multiplies flux values by this smoothly varying factor.\n",
    "\n",
    "This simulates real observational behaviors such as:\n",
    "\n",
    "- changing sky transparency over the night  \n",
    "- drifting calibration during observations  \n",
    "- atmospheric fluctuations  \n",
    "- long-term instrumental sensitivity drifts  \n",
    "\n",
    "Unlike simple scaling, this method allows different parts of the light curve to be modified differently, while still following a realistic smooth trend.\n",
    "\n",
    "**Why it matters:**  \n",
    "Real telescope data is rarely perfectly stable‚Äîbrightness can drift up or down slowly due to observing conditions. Models trained with brightness warping are better at ignoring such non-astrophysical variations.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚≠ê **Why These Functions Are Important for the Research**\n",
    "Astronomical time-series datasets often contain only a limited number of clean observations. Machine-learning models trained on small, highly consistent datasets may struggle when exposed to real survey data containing noise, variability, or calibration issues.\n",
    "\n",
    "These augmentations:\n",
    "\n",
    "- **increase dataset size** without changing the underlying astrophysical behavior  \n",
    "- **simulate real observation conditions**, improving model generalization  \n",
    "- **help machine-learning models become more robust** against noise and calibration drift  \n",
    "- **preserve the scientific structure** of the brightness curve  \n",
    "\n",
    "By incorporating both uniform scaling and smooth warping, the researcher creates a training dataset that better reflects the complexity of true astronomical observations.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "268f7be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude_scaling(df, flux_col, scale_range=(0.8,1.2), seed=None):\n",
    "    if flux_col is None or flux_col not in df.columns:\n",
    "        return df\n",
    "    rng = np.random.default_rng(seed)\n",
    "    factor = float(rng.uniform(scale_range[0], scale_range[1]))\n",
    "    df_aug = df.copy()\n",
    "    df_aug[flux_col] = df_aug[flux_col].astype(float) * factor\n",
    "    return df_aug\n",
    "\n",
    "def brightness_warping(df, time_col, flux_col, n_knots=3, warp_scale=0.1, seed=None):\n",
    "    \"\"\"Apply a smooth multiplicative warp across time using piecewise linear interpolation.\n",
    "    Handles datetime-like time columns by converting to seconds for interpolation.\"\"\"\n",
    "    if flux_col is None or flux_col not in df.columns:\n",
    "        return df\n",
    "    df_aug = df.copy()\n",
    "    # try to get numeric times in seconds\n",
    "    use_datetime = False\n",
    "    try:\n",
    "        times_dt = pd.to_datetime(df_aug[time_col], errors='coerce')\n",
    "        if not times_dt.isna().all():\n",
    "            times = times_dt.astype('datetime64[ns]').astype('int64') / 1e9\n",
    "            use_datetime = True\n",
    "        else:\n",
    "            times = df_aug[time_col].astype(float).values\n",
    "    except Exception:\n",
    "        times = df_aug[time_col].astype(float).values\n",
    "    tmin, tmax = np.min(times), np.max(times)\n",
    "    if tmax == tmin:\n",
    "        return df_aug\n",
    "    knots = np.linspace(tmin, tmax, n_knots)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    knot_factors = rng.normal(loc=1.0, scale=warp_scale, size=len(knots))\n",
    "    factors = np.interp(times, knots, knot_factors)\n",
    "    df_aug[flux_col] = df_aug[flux_col].astype(float) * factors\n",
    "    return df_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cea9b9",
   "metadata": {},
   "source": [
    "## 4.3 Noise Augmentations\n",
    "- Gaussian noise injection to flux.\n",
    "- Photometric uncertainty simulation: add noise based on provided flux_err or an assumed S/N model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732059aa",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üìå Cell Description: Noise-Based Augmentation to Simulate Real Telescope Measurement Errors</summary>\n",
    "\n",
    "This cell adds two augmentation techniques that introduce **realistic noise** into the brightness (flux) measurements. In astronomy, every observation contains some amount of noise because telescopes, detectors, and the atmosphere are not perfect. These augmentations simulate such imperfections so that machine-learning models learn to handle real, noisy survey data instead of only clean values.\n",
    "\n",
    "Both functions operate carefully: they add noise without destroying the overall scientific pattern of the light curve. This makes the augmented data more realistic and improves model robustness.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **1. `gaussian_noise_injection()` ‚Äì Adds Random Noise Proportional to Flux**\n",
    "- Adds Gaussian (normal-distributed) noise to each flux value.  \n",
    "- Noise magnitude is a small fraction (default 5%) of the flux value.  \n",
    "- Ensures noise is proportional: brighter objects get slightly stronger noise, which matches real telescope physics.  \n",
    "- Prevents zero-noise cases with a tiny minimum value.\n",
    "\n",
    "**What it simulates:**  \n",
    "Natural detector noise, atmospheric variation, background noise, and uncertainties that occur during image processing.\n",
    "\n",
    "**Why it's useful:**  \n",
    "Machine-learning models must learn that real astronomical signals always include some noise and are never perfectly smooth.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **2. `photometric_uncertainty_simulation()` ‚Äì Uses Real Flux Error Measurements**\n",
    "This method is even more physically realistic.\n",
    "\n",
    "- If a **flux error column** (flux_err) exists, noise is drawn using that actual uncertainty.  \n",
    "- This means each observation receives noise equal to its measured error bar‚Äîexactly how astronomers treat real photometric data.  \n",
    "- If flux_err is not available, a fallback model estimates uncertainty using:  \n",
    "  - a fractional error (5%) and  \n",
    "  - Poisson-like photon noise (which increases with brightness).\n",
    "\n",
    "**What it simulates:**  \n",
    "True measurement errors that result from:  \n",
    "- detector sensitivity  \n",
    "- background sky brightness  \n",
    "- photon counting noise  \n",
    "- observational conditions\n",
    "\n",
    "**Why it's useful:**  \n",
    "It brings the augmented data even closer to real ZTF survey conditions.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚≠ê **Why These Functions Are Important for the Research**\n",
    "Noise simulation is a critical part of astroinformatics and astronomical ML workflows because:\n",
    "\n",
    "- Real telescope data is **never clean**‚Äînoise is a core part of the measurement process.  \n",
    "- Models trained only on smooth, noise-free data perform poorly on real observations.  \n",
    "- Injecting realistic noise helps models learn stable patterns rather than memorizing perfect curves.  \n",
    "- These augmentations significantly improve **generalization, robustness, and scientific credibility** of the ML pipeline.  \n",
    "- They prepare the model for real-world deployment on ZTF or any other survey data.\n",
    "\n",
    "Together, these two functions mimic both general noise and physically grounded photometric errors, producing augmented datasets that closely resemble real astronomical observations.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20503144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise_injection(df, flux_col, sigma_fraction=0.05, seed=None):\n",
    "    if flux_col is None or flux_col not in df.columns:\n",
    "        return df\n",
    "    rng = np.random.default_rng(seed)\n",
    "    flux = df[flux_col].astype(float).values\n",
    "    sigma = np.maximum(np.abs(flux) * sigma_fraction, 1e-8)\n",
    "    noise = rng.normal(loc=0.0, scale=sigma)\n",
    "    df_aug = df.copy()\n",
    "    df_aug[flux_col] = flux + noise\n",
    "    return df_aug\n",
    "\n",
    "def photometric_uncertainty_simulation(df, flux_col, flux_err_col=None, seed=None):\n",
    "    \"\"\"If a flux_err column exists, perturb flux by that uncertainty; otherwise assume poisson or fractional error.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    if flux_col is None or flux_col not in df.columns:\n",
    "        return df\n",
    "    df_aug = df.copy()\n",
    "    flux = df_aug[flux_col].astype(float).values\n",
    "    if flux_err_col and flux_err_col in df_aug.columns:\n",
    "        err = df_aug[flux_err_col].astype(float).values\n",
    "        noise = rng.normal(loc=0.0, scale=err)\n",
    "        df_aug[flux_col] = flux + noise\n",
    "    else:\n",
    "        rel_err = 0.05\n",
    "        sigma = np.maximum(np.abs(flux) * rel_err, np.sqrt(np.maximum(flux, 0)) * 0.1 + 1e-8)\n",
    "        noise = rng.normal(loc=0.0, scale=sigma)\n",
    "        df_aug[flux_col] = flux + noise\n",
    "    return df_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c635e50d",
   "metadata": {},
   "source": [
    "## 4.4 Multi-band Transformations\n",
    "- Filter-dependent transformations: apply different augmentation strengths per band.\n",
    "- Dropout of random bands: remove observations from random filters to mimic missing bands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e6b5f1",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üìå Cell Description: Augmentations Based on Telescope Filters and Missing Band Simulation</summary>\n",
    "\n",
    "This cell defines two augmentation techniques that specifically target **filter-dependent behaviour** in astronomical surveys. Modern telescopes, including ZTF, observe the sky through different optical filters (g, r, i, etc.). Each filter captures light in a different wavelength range, and brightness values can vary between filters due to both astrophysical reasons and instrument-related factors.\n",
    "\n",
    "These augmentations simulate real observational situations where brightness varies from filter to filter, or where data from certain filters may be missing. Both methods help create a more realistic and robust dataset for machine-learning models.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **1. `filter_dependent_transform()` ‚Äì Apply Filter-Specific Brightness Scaling**\n",
    "- Identifies all unique filters (e.g., g, r, i).  \n",
    "- Applies a separate multiplicative factor to the brightness (flux) values of each filter.  \n",
    "- Factors may be provided manually, or sampled from a small default range (0.9‚Äì1.1).  \n",
    "- Creates realistic differences between filters without changing the overall light-curve shape.\n",
    "\n",
    "**What it simulates:**\n",
    "- Different sensitivity levels for each filter.  \n",
    "- Calibration differences between wavelength bands.  \n",
    "- Small color-dependent brightness variations.  \n",
    "\n",
    "**Why it matters:**  \n",
    "Astronomical objects often look slightly brighter or fainter depending on the filter used. This augmentation teaches ML models to handle these natural variations.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **2. `random_band_dropout()` ‚Äì Randomly Remove Observations From Certain Filters**\n",
    "- Randomly removes a fraction of rows (default 20%) across the dataset.  \n",
    "- Simulates **missing data** in certain wavelength bands.  \n",
    "- Mirrors real-world issues such as:  \n",
    "  - cloudy observations in only one filter  \n",
    "  - incomplete multi-band coverage  \n",
    "  - technical problems affecting specific bands  \n",
    "- Produces more realistic and challenging datasets for models.\n",
    "\n",
    "**Why it matters:**  \n",
    "Real telescope datasets often contain incomplete band coverage. A model trained only on perfectly complete multi-band data will perform poorly when real data has missing filter measurements.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚≠ê **Why These Functions Are Important for the Research**\n",
    "Astronomical surveys rarely capture perfect multi-band light curves. Brightness can differ by filter, and some filters may be missing entirely. These augmentations address these real-world issues:\n",
    "\n",
    "- **Improves robustness:** Models learn to handle missing filters or inconsistent brightness.  \n",
    "- **Increases training diversity:** Prevents overfitting to one ‚Äúideal‚Äù pattern of data.  \n",
    "- **Simulates telescope realities:** Including calibration differences, sensitivity variations, and partial filter coverage.  \n",
    "- **Enhances generalization:** Models become more prepared for unpredictable observation conditions.\n",
    "\n",
    "Together, these augmentations help create datasets that closely resemble real ZTF observations, improving the scientific and practical value of the machine-learning system.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d70805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dependent_transform(df, flux_col, filter_col, per_filter_scale=None, seed=None):\n",
    "    \"\"\"Apply a multiplicative factor per filter. `per_filter_scale` is a dict {filter: (min,max)} or None to sample small variations.\"\"\"\n",
    "    if flux_col is None or flux_col not in df.columns or filter_col is None or filter_col not in df.columns:\n",
    "        return df\n",
    "    df_aug = df.copy()\n",
    "    rng = np.random.default_rng(seed)\n",
    "    unique_filters = df_aug[filter_col].dropna().unique()\n",
    "    for f in unique_filters:\n",
    "        mask = df_aug[filter_col] == f\n",
    "        if per_filter_scale and f in per_filter_scale:\n",
    "            lo, hi = per_filter_scale[f]\n",
    "            factor = float(rng.uniform(lo, hi))\n",
    "        else:\n",
    "            factor = float(rng.uniform(0.9, 1.1))\n",
    "        df_aug.loc[mask, flux_col] = df_aug.loc[mask, flux_col].astype(float) * factor\n",
    "    return df_aug\n",
    "\n",
    "def random_band_dropout(df, filter_col, dropout_prob=0.2, seed=None):\n",
    "    \"\"\"Randomly drop a fraction of observations for some bands. Returns a copy where dropped rows are removed.\"\"\"\n",
    "    if filter_col is None or filter_col not in df.columns:\n",
    "        return df\n",
    "    rng = np.random.default_rng(seed)\n",
    "    df_aug = df.copy()\n",
    "    mask = rng.random(size=df_aug.shape[0]) < dropout_prob\n",
    "    df_aug = df_aug.loc[~mask].reset_index(drop=True)\n",
    "    return df_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c2aa61",
   "metadata": {},
   "source": [
    "## Utilities: apply augmentations to grouped time-series and create contrastive pairs\n",
    "The following helper applies augmentations per object (grouped by `id_col`) and returns a concatenated augmented dataset. You can call augmentations sequentially (composition) to create positive pairs for contrastive learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd70a63b",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üìå Cell Description: Group-Level Augmentation, Dataset Augmentation, and Contrastive Pair Generation</summary>\n",
    "\n",
    "This cell defines three powerful utilities that apply augmentation at the **object level** rather than the entire dataset. Astronomical surveys usually contain multiple observations for each celestial object (identified by an object ID). Since these observations form meaningful sequences (light curves), augmentations must be applied **per object**, not randomly across the entire dataset. These utilities allow flexible, modular augmentation pipelines that respect object boundaries and scientific structure.\n",
    "\n",
    "The functions also support **contrastive learning**, a modern machine-learning technique where the model learns by comparing two different augmented versions of the same object. This mimics the SimCLR and self-supervised learning approaches widely used in advanced data science.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **1. `apply_to_group()` ‚Äì Apply Multiple Augmentations to a Single Object**\n",
    "- Takes one object's time-series (one group).  \n",
    "- Applies a sequence of augmentation functions.  \n",
    "- Each augmentation can have its own parameters.  \n",
    "- Ensures augmentations are applied cleanly and in order.  \n",
    "- Returns a new, fully augmented version of that object‚Äôs sequence.\n",
    "\n",
    "**Why it matters:**  \n",
    "Astronomical light curves must be augmented **per object**. Applying augmentations at the row-level would break the scientific time-series structure.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **2. `augment_dataset()` ‚Äì Apply Augmentation to the Entire Dataset Object-by-Object**\n",
    "This is the **master augmentation function**.\n",
    "\n",
    "- Detects each object using an ID column (e.g., object_id, source_id).  \n",
    "- Groups the dataset so each object's light curve is processed independently.  \n",
    "- Optionally sorts each object‚Äôs data by time (ensures chronological order).  \n",
    "- Applies all chosen augmentations to each group.  \n",
    "- Supports **sample_frac**, which controls the percentage of objects to augment.  \n",
    "- Returns a fully augmented dataset containing realistic, object-level sequences.\n",
    "\n",
    "**What it ensures:**\n",
    "- Augmentations never mix data from different objects.  \n",
    "- Temporal order is preserved.  \n",
    "- Output remains scientifically valid and consistent with telescope behavior.  \n",
    "\n",
    "**Why it's important:**  \n",
    "Real astronomical machine learning requires understanding each object's behaviour across time, so augmentation must respect object identity and temporal sequence.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **3. `make_contrastive_pair()` ‚Äì Create Two Augmented Views of the Same Object**\n",
    "This function is used in **contrastive learning**, a state-of-the-art technique in deep learning.\n",
    "\n",
    "- Takes one object's time-series.  \n",
    "- Applies two *different* augmentation pipelines:  \n",
    "  - **AugA** (first view)  \n",
    "  - **AugB** (second view)  \n",
    "- Returns two augmented versions of the same object.\n",
    "\n",
    "In contrastive learning, the model learns that:\n",
    "\n",
    "- The two augmented sequences represent the *same astronomical object*, even though their appearance is slightly different due to augmentation.  \n",
    "- Different objects should still have different representations.\n",
    "\n",
    "**Why it matters:**  \n",
    "This is the foundation of **self-supervised representation learning**, helping the model learn reliable features even without labels.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚≠ê **Why These Functions Are Important for the Research**\n",
    "These utilities together make this pipeline extremely powerful:\n",
    "\n",
    "- **Supports object-level data augmentation**, essential for astronomical time-series.  \n",
    "- Ensures augmentations do not break object identity or scientific meaning.  \n",
    "- Allows creating large numbers of augmented light curves for training.  \n",
    "- Enables **contrastive learning**, a cutting-edge approach for building strong models from unlabeled data.  \n",
    "- Makes the augmentation pipeline modular, reusable, and easy to extend.  \n",
    "- Prepares the dataset for advanced methods like SimCLR, BYOL, or contrastive autoencoders.  \n",
    "- Mimics realistic observation variations while preserving astrophysical signals.  \n",
    "\n",
    "Overall, this block forms the *backbone* of the augmentation and contrastive learning system for astronomical machine learning.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb02701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_to_group(df_group, funcs):\n",
    "    \"\"\"Apply a list of augmentation functions (each accepts and returns a DataFrame for the group).\"\"\"\n",
    "    g = df_group.copy().reset_index(drop=True)\n",
    "    for f, kwargs in funcs:\n",
    "        g = f(g, **kwargs) if kwargs is not None else f(g)\n",
    "    return g\n",
    "\n",
    "def augment_dataset(df, id_col=None, funcs_per_group=None, sample_frac=1.0, random_state=None):\n",
    "    \"\"\"Apply augmentations per object id and return augmented examples.\n",
    "    - `funcs_per_group` should be a list of tuples (func, kwargs) to apply to each group.\"\"\"\n",
    "    if funcs_per_group is None:\n",
    "        return df\n",
    "    if id_col is None or id_col not in df.columns:\n",
    "        # treat whole DF as one sequence\n",
    "        return apply_to_group(df, funcs_per_group)\n",
    "    groups = df.groupby(id_col)\n",
    "    out_rows = []\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    ids = list(groups.groups.keys())\n",
    "    if sample_frac < 1.0:\n",
    "        k = max(1, int(len(ids) * sample_frac))\n",
    "        ids = rng.choice(ids, size=k, replace=False).tolist()\n",
    "    for objid in ids:\n",
    "        g = groups.get_group(objid)\n",
    "        g_sorted = sort_by_time(g, detect_columns(g)['time'])\n",
    "        g_aug = apply_to_group(g_sorted, funcs_per_group)\n",
    "        out_rows.append(g_aug)\n",
    "    if len(out_rows) == 0:\n",
    "        return pd.DataFrame(columns=df.columns)\n",
    "    return pd.concat(out_rows, ignore_index=True)\n",
    "\n",
    "def make_contrastive_pair(group_df, augA, augB):\n",
    "    a = apply_to_group(group_df, augA)\n",
    "    b = apply_to_group(group_df, augB)\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0d116e",
   "metadata": {},
   "source": [
    "## Example usage and saving augmented samples\n",
    "Below is an example that loads the cleaned dataset, selects a small sample of objects, applies a pipeline of augmentations, and saves augmented CSVs for later training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00634ef6",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üìå Cell Description: Example Usage of the Full Augmentation Pipeline + Saving Contrastive Samples</summary>\n",
    "\n",
    "This cell demonstrates how all the previously defined augmentation tools come together to generate **augmented astronomical time-series data**. It loads the cleaned dataset, detects important columns (time, flux, filter, object ID), selects a subset of objects, applies two different augmentation pipelines, and finally saves the resulting augmented datasets.\n",
    "\n",
    "The purpose of this cell is to provide a **practical example** of how the augmentation functions are used in real workflows, especially for **contrastive learning**, where two different augmented views of the same object are required. This step prepares training data for machine-learning models that rely on self-supervised learning or contrastive objectives.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **Step-by-Step Summary (Simple & Attractive)**\n",
    "\n",
    "- **Loads the cleaned dataset**, ensuring preprocessing has been completed.  \n",
    "- **Automatically detects key columns** using `detect_columns()`, such as:\n",
    "  - object ID  \n",
    "  - time  \n",
    "  - flux  \n",
    "  - filter  \n",
    "- **Selects up to 50 unique objects** (if IDs exist).  \n",
    "- **Defines two augmentation pipelines**, each applying different transformations:\n",
    "  - **AugA**: temporal jitter + brightness scaling + Gaussian noise  \n",
    "  - **AugB**: time shifting + smooth brightness warping + photometric uncertainty  \n",
    "- **Applies augmentations object-by-object** using `augment_dataset()`.  \n",
    "- **Generates two augmented datasets**, each containing realistic variations of the same astronomical light curves.  \n",
    "- **Saves both outputs** (`augmented_A_sample.csv`, `augmented_B_sample.csv`) for later use in training models.  \n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **Purpose of AugA and AugB (Contrastive Learning Friendly)**\n",
    "\n",
    "- **AugA** applies small, local modifications.  \n",
    "- **AugB** applies larger, more global distortions.  \n",
    "- Together, they create two *different but related* views of each object.  \n",
    "- Perfect for contrastive learning approaches like:  \n",
    "  - SimCLR  \n",
    "  - BYOL  \n",
    "  - MoCo  \n",
    "  - Contrastive autoencoders  \n",
    "\n",
    "This helps the model learn the true underlying structure of astronomical light curves.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚≠ê **Why This Cell Is Important for the Research**\n",
    "\n",
    "This cell performs several essential functions:\n",
    "\n",
    "1. **Demonstrates end-to-end augmentation**  \n",
    "   It ties together all earlier augmentation utilities into a practical workflow.\n",
    "\n",
    "2. **Prepares contrastive pairs for modern ML methods**  \n",
    "   Contrastive learning is one of the most powerful techniques for learning good representations from unlabeled data ‚Äî highly relevant in astronomy where labels are scarce.\n",
    "\n",
    "3. **Ensures augmentations respect object identity and time order**  \n",
    "   This is crucial for maintaining scientific meaning.\n",
    "\n",
    "4. **Generates a rich, diverse training dataset**  \n",
    "   This improves:\n",
    "   - model robustness  \n",
    "   - generalization to new observations  \n",
    "   - performance on real ZTF data containing noise and irregular sampling  \n",
    "\n",
    "5. **Creates outputs that can be directly used for model training**  \n",
    "   The saved CSV files form the basis of further ML experiments.\n",
    "\n",
    "Overall, this cell is the **final integration step** that converts raw cleaned data into scientifically meaningful, augmented datasets ready for advanced machine-learning models.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69c8c003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected columns: {'time': 'obsdate', 'flux': None, 'filt': 'filtercode', 'id': 'ipac_gid'}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2018-03-25 06:35:35+00'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m, in \u001b[0;36mtemporal_jitter\u001b[1;34m(df, time_col, sigma_fraction, seed)\u001b[0m\n\u001b[0;32m     10\u001b[0m times_dt \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[time_col], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m times_s \u001b[38;5;241m=\u001b[39m \u001b[43mtimes_dt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatetime64[ns]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1e9\u001b[39m\n\u001b[0;32m     12\u001b[0m use_datetime \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m times_dt\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39mall()\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m     applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:179\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:720\u001b[0m, in \u001b[0;36mDatetimeArray.astype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_np_dtype(dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;66;03m# pre-2.0 behavior for DTA/DTI was\u001b[39;00m\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;66;03m#  values.tz_convert(\"UTC\").tz_localize(None), which did not match\u001b[39;00m\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;66;03m#  the Series behavior\u001b[39;00m\n\u001b[1;32m--> 720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    721\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use .astype to convert from timezone-aware dtype to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimezone-naive dtype. Use obj.tz_localize(None) or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    723\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobj.tz_convert(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUTC\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).tz_localize(None) instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    724\u001b[0m     )\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    727\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_np_dtype(dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    729\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_unitless(dtype)\n\u001b[0;32m    731\u001b[0m ):\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot use .astype to convert from timezone-aware dtype to timezone-naive dtype. Use obj.tz_localize(None) or obj.tz_convert('UTC').tz_localize(None) instead.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 29\u001b[0m\n\u001b[0;32m     23\u001b[0m augB \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     24\u001b[0m     (\u001b[38;5;28;01mlambda\u001b[39;00m g, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: random_time_shift(g, cols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m], seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m     25\u001b[0m     (\u001b[38;5;28;01mlambda\u001b[39;00m g, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: brightness_warping(g, cols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m], cols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflux\u001b[39m\u001b[38;5;124m'\u001b[39m], n_knots\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, warp_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.08\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m     26\u001b[0m     (\u001b[38;5;28;01mlambda\u001b[39;00m g, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: photometric_uncertainty_simulation(g, cols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflux\u001b[39m\u001b[38;5;124m'\u001b[39m], flux_err_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m ]\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# create augmented sets (this will return concatenated groups)\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m aug_set_A \u001b[38;5;241m=\u001b[39m \u001b[43maugment_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuncs_per_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_frac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m aug_set_B \u001b[38;5;241m=\u001b[39m augment_dataset(sample_df, id_col\u001b[38;5;241m=\u001b[39mcols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m], funcs_per_group\u001b[38;5;241m=\u001b[39maugB, sample_frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# save examples\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 26\u001b[0m, in \u001b[0;36maugment_dataset\u001b[1;34m(df, id_col, funcs_per_group, sample_frac, random_state)\u001b[0m\n\u001b[0;32m     24\u001b[0m     g \u001b[38;5;241m=\u001b[39m groups\u001b[38;5;241m.\u001b[39mget_group(objid)\n\u001b[0;32m     25\u001b[0m     g_sorted \u001b[38;5;241m=\u001b[39m sort_by_time(g, detect_columns(g)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 26\u001b[0m     g_aug \u001b[38;5;241m=\u001b[39m \u001b[43mapply_to_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_sorted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuncs_per_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     out_rows\u001b[38;5;241m.\u001b[39mappend(g_aug)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out_rows) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m, in \u001b[0;36mapply_to_group\u001b[1;34m(df_group, funcs)\u001b[0m\n\u001b[0;32m      3\u001b[0m g \u001b[38;5;241m=\u001b[39m df_group\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f, kwargs \u001b[38;5;129;01min\u001b[39;00m funcs:\n\u001b[1;32m----> 5\u001b[0m     g \u001b[38;5;241m=\u001b[39m f(g, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m g\n",
      "Cell \u001b[1;32mIn[7], line 19\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(g, **kw)\u001b[0m\n\u001b[0;32m     15\u001b[0m     sample_df \u001b[38;5;241m=\u001b[39m df_all[df_all[idc]\u001b[38;5;241m.\u001b[39misin(sel_ids)]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# define two augmentation pipelines for contrastive positives\u001b[39;00m\n\u001b[0;32m     18\u001b[0m augA \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m---> 19\u001b[0m     (\u001b[38;5;28;01mlambda\u001b[39;00m g, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: \u001b[43mtemporal_jitter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma_fraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m     20\u001b[0m     (\u001b[38;5;28;01mlambda\u001b[39;00m g, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: magnitude_scaling(g, cols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflux\u001b[39m\u001b[38;5;124m'\u001b[39m], scale_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.95\u001b[39m,\u001b[38;5;241m1.05\u001b[39m), seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m     21\u001b[0m     (\u001b[38;5;28;01mlambda\u001b[39;00m g, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: gaussian_noise_injection(g, cols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflux\u001b[39m\u001b[38;5;124m'\u001b[39m], sigma_fraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.03\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     22\u001b[0m ]\n\u001b[0;32m     23\u001b[0m augB \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     24\u001b[0m     (\u001b[38;5;28;01mlambda\u001b[39;00m g, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: random_time_shift(g, cols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m], seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m     25\u001b[0m     (\u001b[38;5;28;01mlambda\u001b[39;00m g, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: brightness_warping(g, cols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m], cols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflux\u001b[39m\u001b[38;5;124m'\u001b[39m], n_knots\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, warp_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.08\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m     26\u001b[0m     (\u001b[38;5;28;01mlambda\u001b[39;00m g, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: photometric_uncertainty_simulation(g, cols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflux\u001b[39m\u001b[38;5;124m'\u001b[39m], flux_err_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m ]\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# create augmented sets (this will return concatenated groups)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 14\u001b[0m, in \u001b[0;36mtemporal_jitter\u001b[1;34m(df, time_col, sigma_fraction, seed)\u001b[0m\n\u001b[0;32m     12\u001b[0m     use_datetime \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m times_dt\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m---> 14\u001b[0m     times_s \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtime_col\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     15\u001b[0m     use_datetime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     16\u001b[0m times \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(times_s, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6639\u001b[0m     ]\n\u001b[0;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '2018-03-25 06:35:35+00'"
     ]
    }
   ],
   "source": [
    "# Example usage (will run if the cleaned dataset exists in workspace)\n",
    "DATA_CLEANED = 'ztf_image_search_results_full_cleaned.csv'\n",
    "if not os.path.exists(DATA_CLEANED):\n",
    "    print(DATA_CLEANED, 'not found in workspace ‚Äî update path or run preprocessing first')\n",
    "else:\n",
    "    df_all = pd.read_csv(DATA_CLEANED)\n",
    "    cols = detect_columns(df_all)\n",
    "    print('Detected columns:', cols)\n",
    "    idc = cols['id']\n",
    "    if idc is None or idc not in df_all.columns:\n",
    "        sample_df = df_all\n",
    "    else:\n",
    "        unique_ids = df_all[idc].dropna().unique()\n",
    "        sel_ids = unique_ids[:50] if len(unique_ids) > 50 else unique_ids\n",
    "        sample_df = df_all[df_all[idc].isin(sel_ids)].reset_index(drop=True)\n",
    "\n",
    "    # define two augmentation pipelines for contrastive positives\n",
    "    augA = [\n",
    "        (lambda g, **kw: temporal_jitter(g, cols['time'], sigma_fraction=0.01, seed=42), None),\n",
    "        (lambda g, **kw: magnitude_scaling(g, cols['flux'], scale_range=(0.95,1.05), seed=42), None),\n",
    "        (lambda g, **kw: gaussian_noise_injection(g, cols['flux'], sigma_fraction=0.03, seed=42), None)\n",
    "    ]\n",
    "    augB = [\n",
    "        (lambda g, **kw: random_time_shift(g, cols['time'], seed=24), None),\n",
    "        (lambda g, **kw: brightness_warping(g, cols['time'], cols['flux'], n_knots=4, warp_scale=0.08, seed=24), None),\n",
    "        (lambda g, **kw: photometric_uncertainty_simulation(g, cols['flux'], flux_err_col=None, seed=24), None)\n",
    "    ]\n",
    "    # create augmented sets (this will return concatenated groups)\n",
    "    aug_set_A = augment_dataset(sample_df, id_col=cols['id'], funcs_per_group=augA, sample_frac=1.0, random_state=42)\n",
    "    aug_set_B = augment_dataset(sample_df, id_col=cols['id'], funcs_per_group=augB, sample_frac=1.0, random_state=24)\n",
    "    # save examples\n",
    "    aug_set_A.to_csv('augmented_A_sample.csv', index=False)\n",
    "    aug_set_B.to_csv('augmented_B_sample.csv', index=False)\n",
    "    print('Saved augmented_A_sample.csv and augmented_B_sample.csv (sample)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
