{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb6c1a6f",
   "metadata": {},
   "source": [
    "# Data Augmentation for Contrastive Learning (Astronomy)\n",
    "\n",
    "This notebook implements domain-aware augmentations suitable for contrastive learning on astronomical time-series / multi-band observations. Each augmentation is provided as a function that accepts per-object time-series data (pandas DataFrame) and returns an augmented copy.\n",
    "\n",
    "Assumptions: the input DataFrame should contain at least an identifier for the source (e.g. `object_id`), a time column (`time`, `jd`, `mjd`, or `obsdate`), a brightness column (`flux` or `mag`), and a filter/band column (`filter`). Each function performs checks and falls back gracefully if columns are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8def02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and helper utilities\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "# Small helper: find time / brightness / filter cols\n",
    "def detect_columns(df):\n",
    "    cols_lower = [c.lower() for c in df.columns]\n",
    "    time_col = next((c for c in df.columns if c.lower() in ['time','obsdate','jd','mjd','epoch']), None)\n",
    "    flux_col = next((c for c in df.columns if c.lower() in ['flux','flux_calib','mag','mag_calib','instrumental_flux']), None)\n",
    "    filter_col = next((c for c in df.columns if 'filter' in c.lower() or 'band' in c.lower()), None)\n",
    "    id_col = next((c for c in df.columns if c.lower() in ['object_id','objid','id','source_id','ipac_gid']), None)\n",
    "    # return 'filter' key (was 'filt' previously) for consistency with augmentation functions\n",
    "    return dict(time=time_col, flux=flux_col, filter=filter_col, id=id_col)\n",
    "\n",
    "# Utility: ensure DataFrame sorted by time for each object\n",
    "def sort_by_time(df, time_col):\n",
    "    if time_col is None or time_col not in df.columns:\n",
    "        return df\n",
    "    try:\n",
    "        return df.sort_values(by=[time_col]).reset_index(drop=True)\n",
    "    except Exception:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b672d9e",
   "metadata": {},
   "source": [
    "## 4.1 Temporal Augmentations\n",
    "- Temporal jittering: add small random noise to timestamps.\n",
    "- Random time shifts: shift the whole sequence by a random amount.\n",
    "- Random cropping: return a contiguous partial subsequence to simulate partial coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ade4ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_jitter(df, time_col, sigma_fraction=0.01, seed=None):\n",
    "    \"\"\"Add Gaussian jitter to timestamps (fraction of median cadence).\n",
    "    Handles datetime-like columns by converting to seconds since epoch, applying jitter,\n",
    "    and converting back to datetimes. Returns DataFrame with same time dtype where possible.\"\"\"\n",
    "    if time_col is None or time_col not in df.columns:\n",
    "        return df\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # try to convert to datetime; if not possible, fall back to numeric as before\n",
    "    try:\n",
    "        times_dt = pd.to_datetime(df[time_col], errors='coerce')\n",
    "        times_s = times_dt.astype('datetime64[ns]').astype('int64') / 1e9\n",
    "        use_datetime = not times_dt.isna().all()\n",
    "    except Exception:\n",
    "        times_s = df[time_col].astype(float).values\n",
    "        use_datetime = False\n",
    "    times = np.array(times_s, dtype=float)\n",
    "    diffs = np.diff(np.sort(times)) if len(times) > 1 else np.array([1.0])\n",
    "    median_cadence = np.median(diffs) if len(diffs) > 0 else 1.0\n",
    "    sigma = sigma_fraction * median_cadence\n",
    "    jitter = rng.normal(loc=0.0, scale=sigma, size=times.shape)\n",
    "    new_times = times + jitter\n",
    "    df_aug = df.copy()\n",
    "    if use_datetime:\n",
    "        df_aug[time_col] = pd.to_datetime(new_times, unit='s')\n",
    "    else:\n",
    "        df_aug[time_col] = new_times\n",
    "    return df_aug\n",
    "\n",
    "def random_time_shift(df, time_col, shift_range=None, seed=None):\n",
    "    \"\"\"Shift the entire sequence by a random amount. shift_range can be (min,max) in same units as time_col. If None, uses +/- 0.5 * duration.\"\"\"\n",
    "    if time_col is None or time_col not in df.columns:\n",
    "        return df\n",
    "    rng = np.random.default_rng(seed)\n",
    "    try:\n",
    "        times_dt = pd.to_datetime(df[time_col], errors='coerce')\n",
    "        times_s = times_dt.astype('datetime64[ns]').astype('int64') / 1e9\n",
    "        use_datetime = not times_dt.isna().all()\n",
    "    except Exception:\n",
    "        times_s = df[time_col].astype(float).values\n",
    "        use_datetime = False\n",
    "    times = np.array(times_s, dtype=float)\n",
    "    duration = times.max() - times.min() if len(times) > 1 else 0.0\n",
    "    if shift_range is None:\n",
    "        shift_range = (-0.5 * duration, 0.5 * duration)\n",
    "    shift = float(rng.uniform(shift_range[0], shift_range[1]))\n",
    "    new_times = times + shift\n",
    "    df_aug = df.copy()\n",
    "    if use_datetime:\n",
    "        df_aug[time_col] = pd.to_datetime(new_times, unit='s')\n",
    "    else:\n",
    "        df_aug[time_col] = new_times\n",
    "    return df_aug\n",
    "\n",
    "def random_crop(df, time_col, min_fraction=0.5, seed=None):\n",
    "    \"\"\"Return a contiguous subsequence of the timeseries (per-object).\"\"\"\n",
    "    if time_col is None or time_col not in df.columns:\n",
    "        return df\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(df)\n",
    "    if n < 2:\n",
    "        return df\n",
    "    min_len = max(1, int(np.ceil(min_fraction * n)))\n",
    "    start = int(rng.integers(0, n - min_len + 1))\n",
    "    end = int(rng.integers(start + min_len, n + 1))\n",
    "    return df.iloc[start:end].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdef201b",
   "metadata": {},
   "source": [
    "## 4.2 Magnitude Augmentations\n",
    "- Magnitude scaling: multiply flux by a random factor.\n",
    "- Brightness warping: apply smooth multiplicative warp across time to simulate calibration/seeing changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "268f7be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude_scaling(df, flux_col, scale_range=(0.8,1.2), seed=None):\n",
    "    if flux_col is None or flux_col not in df.columns:\n",
    "        return df\n",
    "    rng = np.random.default_rng(seed)\n",
    "    factor = float(rng.uniform(scale_range[0], scale_range[1]))\n",
    "    df_aug = df.copy()\n",
    "    df_aug[flux_col] = df_aug[flux_col].astype(float) * factor\n",
    "    return df_aug\n",
    "\n",
    "def brightness_warping(df, time_col, flux_col, n_knots=3, warp_scale=0.1, seed=None):\n",
    "    \"\"\"Apply a smooth multiplicative warp across time using piecewise linear interpolation.\n",
    "    Handles datetime-like time columns by converting to seconds for interpolation.\"\"\"\n",
    "    if flux_col is None or flux_col not in df.columns:\n",
    "        return df\n",
    "    df_aug = df.copy()\n",
    "    # try to get numeric times in seconds\n",
    "    use_datetime = False\n",
    "    try:\n",
    "        times_dt = pd.to_datetime(df_aug[time_col], errors='coerce')\n",
    "        if not times_dt.isna().all():\n",
    "            times = times_dt.astype('datetime64[ns]').astype('int64') / 1e9\n",
    "            use_datetime = True\n",
    "        else:\n",
    "            times = df_aug[time_col].astype(float).values\n",
    "    except Exception:\n",
    "        times = df_aug[time_col].astype(float).values\n",
    "    tmin, tmax = np.min(times), np.max(times)\n",
    "    if tmax == tmin:\n",
    "        return df_aug\n",
    "    knots = np.linspace(tmin, tmax, n_knots)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    knot_factors = rng.normal(loc=1.0, scale=warp_scale, size=len(knots))\n",
    "    factors = np.interp(times, knots, knot_factors)\n",
    "    df_aug[flux_col] = df_aug[flux_col].astype(float) * factors\n",
    "    return df_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cea9b9",
   "metadata": {},
   "source": [
    "## 4.3 Noise Augmentations\n",
    "- Gaussian noise injection to flux.\n",
    "- Photometric uncertainty simulation: add noise based on provided flux_err or an assumed S/N model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20503144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise_injection(df, flux_col, sigma_fraction=0.05, seed=None):\n",
    "    if flux_col is None or flux_col not in df.columns:\n",
    "        return df\n",
    "    rng = np.random.default_rng(seed)\n",
    "    flux = df[flux_col].astype(float).values\n",
    "    sigma = np.maximum(np.abs(flux) * sigma_fraction, 1e-8)\n",
    "    noise = rng.normal(loc=0.0, scale=sigma)\n",
    "    df_aug = df.copy()\n",
    "    df_aug[flux_col] = flux + noise\n",
    "    return df_aug\n",
    "\n",
    "def photometric_uncertainty_simulation(df, flux_col, flux_err_col=None, seed=None):\n",
    "    \"\"\"If a flux_err column exists, perturb flux by that uncertainty; otherwise assume poisson or fractional error.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    if flux_col is None or flux_col not in df.columns:\n",
    "        return df\n",
    "    df_aug = df.copy()\n",
    "    flux = df_aug[flux_col].astype(float).values\n",
    "    if flux_err_col and flux_err_col in df_aug.columns:\n",
    "        err = df_aug[flux_err_col].astype(float).values\n",
    "        noise = rng.normal(loc=0.0, scale=err)\n",
    "        df_aug[flux_col] = flux + noise\n",
    "    else:\n",
    "        rel_err = 0.05\n",
    "        sigma = np.maximum(np.abs(flux) * rel_err, np.sqrt(np.maximum(flux, 0)) * 0.1 + 1e-8)\n",
    "        noise = rng.normal(loc=0.0, scale=sigma)\n",
    "        df_aug[flux_col] = flux + noise\n",
    "    return df_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c635e50d",
   "metadata": {},
   "source": [
    "## 4.4 Multi-band Transformations\n",
    "- Filter-dependent transformations: apply different augmentation strengths per band.\n",
    "- Dropout of random bands: remove observations from random filters to mimic missing bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d70805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dependent_transform(df, flux_col, filter_col, per_filter_scale=None, seed=None):\n",
    "    \"\"\"Apply a multiplicative factor per filter. `per_filter_scale` is a dict {filter: (min,max)} or None to sample small variations.\"\"\"\n",
    "    if flux_col is None or flux_col not in df.columns or filter_col is None or filter_col not in df.columns:\n",
    "        return df\n",
    "    df_aug = df.copy()\n",
    "    rng = np.random.default_rng(seed)\n",
    "    unique_filters = df_aug[filter_col].dropna().unique()\n",
    "    for f in unique_filters:\n",
    "        mask = df_aug[filter_col] == f\n",
    "        if per_filter_scale and f in per_filter_scale:\n",
    "            lo, hi = per_filter_scale[f]\n",
    "            factor = float(rng.uniform(lo, hi))\n",
    "        else:\n",
    "            factor = float(rng.uniform(0.9, 1.1))\n",
    "        df_aug.loc[mask, flux_col] = df_aug.loc[mask, flux_col].astype(float) * factor\n",
    "    return df_aug\n",
    "\n",
    "def random_band_dropout(df, filter_col, dropout_prob=0.2, seed=None):\n",
    "    \"\"\"Randomly drop a fraction of observations for some bands. Returns a copy where dropped rows are removed.\"\"\"\n",
    "    if filter_col is None or filter_col not in df.columns:\n",
    "        return df\n",
    "    rng = np.random.default_rng(seed)\n",
    "    df_aug = df.copy()\n",
    "    mask = rng.random(size=df_aug.shape[0]) < dropout_prob\n",
    "    df_aug = df_aug.loc[~mask].reset_index(drop=True)\n",
    "    return df_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c2aa61",
   "metadata": {},
   "source": [
    "## Utilities: apply augmentations to grouped time-series and create contrastive pairs\n",
    "The following helper applies augmentations per object (grouped by `id_col`) and returns a concatenated augmented dataset. You can call augmentations sequentially (composition) to create positive pairs for contrastive learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb02701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_to_group(df_group, funcs):\n",
    "    \"\"\"Apply a list of augmentation functions (each accepts and returns a DataFrame for the group).\"\"\"\n",
    "    g = df_group.copy().reset_index(drop=True)\n",
    "    for f, kwargs in funcs:\n",
    "        g = f(g, **kwargs) if kwargs is not None else f(g)\n",
    "    return g\n",
    "\n",
    "def augment_dataset(df, id_col=None, funcs_per_group=None, sample_frac=1.0, random_state=None):\n",
    "    \"\"\"Apply augmentations per object id and return augmented examples.\n",
    "    - `funcs_per_group` should be a list of tuples (func, kwargs) to apply to each group.\"\"\"\n",
    "    if funcs_per_group is None:\n",
    "        return df\n",
    "    if id_col is None or id_col not in df.columns:\n",
    "        # treat whole DF as one sequence\n",
    "        return apply_to_group(df, funcs_per_group)\n",
    "    groups = df.groupby(id_col)\n",
    "    out_rows = []\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    ids = list(groups.groups.keys())\n",
    "    if sample_frac < 1.0:\n",
    "        k = max(1, int(len(ids) * sample_frac))\n",
    "        ids = rng.choice(ids, size=k, replace=False).tolist()\n",
    "    for objid in ids:\n",
    "        g = groups.get_group(objid)\n",
    "        g_sorted = sort_by_time(g, detect_columns(g)['time'])\n",
    "        g_aug = apply_to_group(g_sorted, funcs_per_group)\n",
    "        out_rows.append(g_aug)\n",
    "    if len(out_rows) == 0:\n",
    "        return pd.DataFrame(columns=df.columns)\n",
    "    return pd.concat(out_rows, ignore_index=True)\n",
    "\n",
    "def make_contrastive_pair(group_df, augA, augB):\n",
    "    a = apply_to_group(group_df, augA)\n",
    "    b = apply_to_group(group_df, augB)\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0d116e",
   "metadata": {},
   "source": [
    "## Example usage and saving augmented samples\n",
    "Below is an example that loads the cleaned dataset, selects a small sample of objects, applies a pipeline of augmentations, and saves augmented CSVs for later training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69c8c003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected columns: {'time': 'obsdate', 'flux': None, 'filt': 'filtercode', 'id': 'ipac_gid'}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2018-03-25 06:35:35+00'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m, in \u001b[0;36mtemporal_jitter\u001b[1;34m(df, time_col, sigma_fraction, seed)\u001b[0m\n\u001b[0;32m     10\u001b[0m times_dt \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[time_col], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m times_s \u001b[38;5;241m=\u001b[39m \u001b[43mtimes_dt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatetime64[ns]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1e9\u001b[39m\n\u001b[0;32m     12\u001b[0m use_datetime \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m times_dt\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39mall()\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m     applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:179\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:720\u001b[0m, in \u001b[0;36mDatetimeArray.astype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_np_dtype(dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;66;03m# pre-2.0 behavior for DTA/DTI was\u001b[39;00m\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;66;03m#  values.tz_convert(\"UTC\").tz_localize(None), which did not match\u001b[39;00m\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;66;03m#  the Series behavior\u001b[39;00m\n\u001b[1;32m--> 720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    721\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use .astype to convert from timezone-aware dtype to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimezone-naive dtype. Use obj.tz_localize(None) or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    723\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobj.tz_convert(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUTC\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).tz_localize(None) instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    724\u001b[0m     )\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    727\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_np_dtype(dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    729\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_unitless(dtype)\n\u001b[0;32m    731\u001b[0m ):\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot use .astype to convert from timezone-aware dtype to timezone-naive dtype. Use obj.tz_localize(None) or obj.tz_convert('UTC').tz_localize(None) instead.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 29\u001b[0m\n\u001b[0;32m     23\u001b[0m augB \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     24\u001b[0m     (\u001b[38;5;28;01mlambda\u001b[39;00m g, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: random_time_shift(g, cols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m], seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m     25\u001b[0m     (\u001b[38;5;28;01mlambda\u001b[39;00m g, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: brightness_warping(g, cols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m], cols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflux\u001b[39m\u001b[38;5;124m'\u001b[39m], n_knots\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, warp_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.08\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m     26\u001b[0m     (\u001b[38;5;28;01mlambda\u001b[39;00m g, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: photometric_uncertainty_simulation(g, cols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflux\u001b[39m\u001b[38;5;124m'\u001b[39m], flux_err_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m ]\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# create augmented sets (this will return concatenated groups)\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m aug_set_A \u001b[38;5;241m=\u001b[39m \u001b[43maugment_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuncs_per_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_frac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m aug_set_B \u001b[38;5;241m=\u001b[39m augment_dataset(sample_df, id_col\u001b[38;5;241m=\u001b[39mcols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m], funcs_per_group\u001b[38;5;241m=\u001b[39maugB, sample_frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# save examples\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 26\u001b[0m, in \u001b[0;36maugment_dataset\u001b[1;34m(df, id_col, funcs_per_group, sample_frac, random_state)\u001b[0m\n\u001b[0;32m     24\u001b[0m     g \u001b[38;5;241m=\u001b[39m groups\u001b[38;5;241m.\u001b[39mget_group(objid)\n\u001b[0;32m     25\u001b[0m     g_sorted \u001b[38;5;241m=\u001b[39m sort_by_time(g, detect_columns(g)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 26\u001b[0m     g_aug \u001b[38;5;241m=\u001b[39m \u001b[43mapply_to_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_sorted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuncs_per_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     out_rows\u001b[38;5;241m.\u001b[39mappend(g_aug)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out_rows) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m, in \u001b[0;36mapply_to_group\u001b[1;34m(df_group, funcs)\u001b[0m\n\u001b[0;32m      3\u001b[0m g \u001b[38;5;241m=\u001b[39m df_group\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f, kwargs \u001b[38;5;129;01min\u001b[39;00m funcs:\n\u001b[1;32m----> 5\u001b[0m     g \u001b[38;5;241m=\u001b[39m f(g, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m g\n",
      "Cell \u001b[1;32mIn[7], line 19\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(g, **kw)\u001b[0m\n\u001b[0;32m     15\u001b[0m     sample_df \u001b[38;5;241m=\u001b[39m df_all[df_all[idc]\u001b[38;5;241m.\u001b[39misin(sel_ids)]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# define two augmentation pipelines for contrastive positives\u001b[39;00m\n\u001b[0;32m     18\u001b[0m augA \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m---> 19\u001b[0m     (\u001b[38;5;28;01mlambda\u001b[39;00m g, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: \u001b[43mtemporal_jitter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma_fraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m     20\u001b[0m     (\u001b[38;5;28;01mlambda\u001b[39;00m g, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: magnitude_scaling(g, cols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflux\u001b[39m\u001b[38;5;124m'\u001b[39m], scale_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.95\u001b[39m,\u001b[38;5;241m1.05\u001b[39m), seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m     21\u001b[0m     (\u001b[38;5;28;01mlambda\u001b[39;00m g, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: gaussian_noise_injection(g, cols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflux\u001b[39m\u001b[38;5;124m'\u001b[39m], sigma_fraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.03\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     22\u001b[0m ]\n\u001b[0;32m     23\u001b[0m augB \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     24\u001b[0m     (\u001b[38;5;28;01mlambda\u001b[39;00m g, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: random_time_shift(g, cols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m], seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m     25\u001b[0m     (\u001b[38;5;28;01mlambda\u001b[39;00m g, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: brightness_warping(g, cols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m], cols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflux\u001b[39m\u001b[38;5;124m'\u001b[39m], n_knots\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, warp_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.08\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m     26\u001b[0m     (\u001b[38;5;28;01mlambda\u001b[39;00m g, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: photometric_uncertainty_simulation(g, cols[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflux\u001b[39m\u001b[38;5;124m'\u001b[39m], flux_err_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m ]\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# create augmented sets (this will return concatenated groups)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 14\u001b[0m, in \u001b[0;36mtemporal_jitter\u001b[1;34m(df, time_col, sigma_fraction, seed)\u001b[0m\n\u001b[0;32m     12\u001b[0m     use_datetime \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m times_dt\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m---> 14\u001b[0m     times_s \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtime_col\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     15\u001b[0m     use_datetime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     16\u001b[0m times \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(times_s, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6639\u001b[0m     ]\n\u001b[0;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '2018-03-25 06:35:35+00'"
     ]
    }
   ],
   "source": [
    "# Example usage (will run if the cleaned dataset exists in workspace)\n",
    "DATA_CLEANED = 'ztf_image_search_results_full_cleaned.csv'\n",
    "if not os.path.exists(DATA_CLEANED):\n",
    "    print(DATA_CLEANED, 'not found in workspace â€” update path or run preprocessing first')\n",
    "else:\n",
    "    df_all = pd.read_csv(DATA_CLEANED)\n",
    "    cols = detect_columns(df_all)\n",
    "    print('Detected columns:', cols)\n",
    "    idc = cols['id']\n",
    "    if idc is None or idc not in df_all.columns:\n",
    "        sample_df = df_all\n",
    "    else:\n",
    "        unique_ids = df_all[idc].dropna().unique()\n",
    "        sel_ids = unique_ids[:50] if len(unique_ids) > 50 else unique_ids\n",
    "        sample_df = df_all[df_all[idc].isin(sel_ids)].reset_index(drop=True)\n",
    "\n",
    "    # define two augmentation pipelines for contrastive positives\n",
    "    augA = [\n",
    "        (lambda g, **kw: temporal_jitter(g, cols['time'], sigma_fraction=0.01, seed=42), None),\n",
    "        (lambda g, **kw: magnitude_scaling(g, cols['flux'], scale_range=(0.95,1.05), seed=42), None),\n",
    "        (lambda g, **kw: gaussian_noise_injection(g, cols['flux'], sigma_fraction=0.03, seed=42), None)\n",
    "    ]\n",
    "    augB = [\n",
    "        (lambda g, **kw: random_time_shift(g, cols['time'], seed=24), None),\n",
    "        (lambda g, **kw: brightness_warping(g, cols['time'], cols['flux'], n_knots=4, warp_scale=0.08, seed=24), None),\n",
    "        (lambda g, **kw: photometric_uncertainty_simulation(g, cols['flux'], flux_err_col=None, seed=24), None)\n",
    "    ]\n",
    "    # create augmented sets (this will return concatenated groups)\n",
    "    aug_set_A = augment_dataset(sample_df, id_col=cols['id'], funcs_per_group=augA, sample_frac=1.0, random_state=42)\n",
    "    aug_set_B = augment_dataset(sample_df, id_col=cols['id'], funcs_per_group=augB, sample_frac=1.0, random_state=24)\n",
    "    # save examples\n",
    "    aug_set_A.to_csv('augmented_A_sample.csv', index=False)\n",
    "    aug_set_B.to_csv('augmented_B_sample.csv', index=False)\n",
    "    print('Saved augmented_A_sample.csv and augmented_B_sample.csv (sample)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
